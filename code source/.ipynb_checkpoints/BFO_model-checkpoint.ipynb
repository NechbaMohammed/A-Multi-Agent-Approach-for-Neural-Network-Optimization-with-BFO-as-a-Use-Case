{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bd41e7",
   "metadata": {},
   "source": [
    "## ENSIAS, Mohamed V University\n",
    "# <center>Project : MULTI AGENT oriented implementation of Neural Networks using an heuristic optimizer ,  BFO as a use case  </center>\n",
    "### <center> Module: SMA </center>\n",
    "### <center> filière  2IA - 2ème année</center> \n",
    "### <center>Group: Mohammed NECHBA, Mohamed MOUHAJIR</center> \n",
    "### <center>Prof. Yasser El Madani El Alami</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "47073695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mesa\n",
    "import numpy as np\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ebbd1c",
   "metadata": {},
   "source": [
    "# 1- Multi-agents based BFO implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b6d88d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent( mesa.Agent):\n",
    "    \n",
    "    \n",
    "    def __init__(self, unique_id, model,n):\n",
    "        \n",
    "       super().__init__(unique_id, model)\n",
    "       self.model = model\n",
    "        \n",
    "        # Generate a random vector of length n with values between low and high \n",
    "       n = self.model.n\n",
    "       low = self.model.lower_bound\n",
    "       high = self.model.upper_bound\n",
    "       random_vector = np.random.uniform(low, high, size=n)\n",
    "        \n",
    "        #Initialize the agent position with this randomly generated vector\n",
    "       self.agent_position = random_vector #the position of the agent in the search space\n",
    "       self.agent_fitness  = self.model.fitness_fct(self.agent_position)# the fitness of the agent\n",
    "    \n",
    "    \n",
    "    def tumble(self):\n",
    "        \"tumble = change the position\"\n",
    "          #Generate a randum vector \"delta\" of size n and whose norme is ||delta||=1\n",
    "        n = self.model.n  # size of vector\n",
    "        delta = np.random.rand(n)  # generate random vector\n",
    "        delta_norm = np.linalg.norm(delta)  # compute norm of vector\n",
    "        delta_normalized = delta / delta_norm  # normalize vector to have norm of 1\n",
    "           \n",
    "            #Retrive the step size of the actual agent\n",
    "        agent_Ci = self.model.Ci[self.unique_id]    \n",
    "             \n",
    "            #Tumble = Update the position\n",
    "        self.agent_position = self.agent_position + agent_Ci * delta_normalized\n",
    "    \n",
    "    \n",
    "    def Best_Position_and_fitness(self):\n",
    "        \"this function retrive the best position and the best fitness value among all agents\"\n",
    "        #get all the positions of agents\n",
    "        positions = np.array( [a.agent_position  for a in self.model.schedule.agents] )\n",
    "        #get all the fitnesses of agents\n",
    "        fitnesses = np.array( [a.agent_fitness for a in self.model.schedule.agents ] )\n",
    "        \n",
    "        #retrive the best position\n",
    "        min_index = np.argmin(fitnesses)\n",
    "        min_value = fitnesses.flat[min_index]\n",
    "        \n",
    "\n",
    "        try :\n",
    "            gbest = positions[min_index] # best position \n",
    "            Gbest = min_value # the corresponding lowest fitness \n",
    "            return gbest,Gbest\n",
    "        \n",
    "        except:\n",
    "            \n",
    "             return self.model.best_position , self.model.best_fitness\n",
    "            \n",
    "              \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def Guassian_Mutation_Operation(self):\n",
    "        #retrive the best position and fitness\n",
    "        gbest, Gbest = self.Best_Position_and_fitness()\n",
    "        \n",
    "        #perform the Gaussian mutation\n",
    "         \n",
    "            #first we'l generate a random nbr following the gaussian distribution\n",
    "        mu = 0  # mean\n",
    "        sigma = 1  # standard deviation\n",
    "        random_number = random.gauss(mu, sigma)\n",
    "        \n",
    "             #Second, we'll generate a new postion\n",
    "        gbestGao =gbest*(1+random_number)\n",
    "           \n",
    "             #computer the fitness of this newly created position\n",
    "        JlastGao = self.model.fitness_fct(gbestGao)     \n",
    "        \n",
    "        if np.linalg.norm(JlastGao) < np.linalg.norm(Gbest) :\n",
    "             Gbest = JlastGao\n",
    "             gbest = gbestGao\n",
    "        \n",
    "        \n",
    "        self.model.best_position = gbest\n",
    "        self.model.best_fitness  = Gbest\n",
    "    \n",
    "    \n",
    "    def swim (self):        \n",
    "        Ns = self.model.Ns    \n",
    "        for i in range (Ns):\n",
    "            self.Guassian_Mutation_Operation()\n",
    "       \n",
    "    #the following method is the one that will be executed by the agent, the above wont be executed\n",
    "    def  step(self):\n",
    "        #1-the agent will change its position\n",
    "        self.tumble()\n",
    "        #2-the agent will search for the best solution to minimize the fitness fct\n",
    "        self.swim()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c878c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFO_Model (mesa.Model):\n",
    "    \"\"\"we deal with a minimization problem using heuristique nature inspired algorithm called\n",
    "          Bacterial Foraging Optimization (BFO)\n",
    "    \"\"\"\n",
    "    \n",
    "    # n : the dimension , e.g  if x_i is in R^3 . Then, n=3.\n",
    "    \n",
    "    def __init__(self,n,fitness_fct,S=10,Ped=0.23,Ned=2,Nre=2, Nc=2,Ns=5,lower_bound=-2**5,upper_bound=2**8):\n",
    "        \n",
    "        self.lower_bound= lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "        \n",
    "        self.schedule= mesa.time.RandomActivation(self) # activate all agents at once in a random order\n",
    "        self.n = n\n",
    "        self.S=S #nbr of agents\n",
    "        self.Ped = Ped #Probability of elimination-dispersal\n",
    "        self.Ned = Ned #nbr of elimination-dispersal loop\n",
    "        self.Nre = Nre #nbr of reproduction\n",
    "        self.Nc = Nc #nbre of chemotaxis\n",
    "        self.Ns = Ns #nbre of swiming\n",
    "        self.Ci = np.random.rand(S) # step size of all agents\n",
    "        self.ch_i = np.random.rand(S) #chaotic sequence\n",
    "        self.fitness_fct = fitness_fct # the objectif funct to be minimized\n",
    "        \n",
    "          # Generate a random vector of length n with values between low and high\n",
    "        n = self.n\n",
    "        low = self.lower_bound\n",
    "        high = self.upper_bound \n",
    "    \n",
    "        \n",
    "        self.best_position =  np.random.uniform(low, high, size=n)  # the best position \n",
    "        self.best_fitness  =  self.fitness_fct(self.best_position)   # the best fitness value\n",
    "        \n",
    "    def createAgents(self):\n",
    "        for i in range(self.S):\n",
    "            a=Agent(i,self,self.n)\n",
    "            try :\n",
    "              self.schedule.add(a)\n",
    "            except :\n",
    "              continue\n",
    "                \n",
    "            \n",
    "    def logistic_map(self):\n",
    "        \"this function create chaotic sequence using the logistic map\"\n",
    "        \n",
    "        mu=4\n",
    "        self.ch_i = np.array([mu*self.ch_i[j]*(1-self.ch_i[j]) for j in range(self.S)])\n",
    "        \n",
    "     \n",
    "        \n",
    "    def chaotic_chemotaxis_step_length_operation(self):\n",
    "        self.Ci=np.array( [self.ch_i[j] * self.Ci[j] for j in range(self.S)  ] )\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    #the following method is the one that will be executed by the model, the above wont be executed    \n",
    "    def step(self):\n",
    "      \n",
    "      #4-elimination-dispersal\n",
    "      for k in range (self.Ned):\n",
    "        random_nbre = random.random()\n",
    "        \n",
    "        if self.Ped > random_nbre :\n",
    "            #eliminate the current position \n",
    "            # and randomly generate new solution in the search space\n",
    "               # Generate a random vector of length n with values between low and high\n",
    "            n = self.n\n",
    "            low = self.lower_bound\n",
    "            high = self.upper_bound \n",
    "            self.best_position =  np.random.uniform(low, high, size=n)  # the best position \n",
    "            self.best_fitness  =  self.fitness_fct(self.best_position)   # the best fitness value\n",
    "           \n",
    "        #3-reproduction\n",
    "        for j in range (self.Nre):\n",
    "          #1-create agents\n",
    "          self.createAgents()\n",
    "\n",
    "          #2-perform chemotaxis for Nc times\n",
    "          for i in range (self.Nc):\n",
    "                self.logistic_map() \n",
    "                self.chaotic_chemotaxis_step_length_operation()\n",
    "                #Advance the model by one step = all agents will do their work simultaniously\n",
    "                self.schedule.step()\n",
    "      \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab68523",
   "metadata": {},
   "source": [
    "Now we'll define the fitness function.\n",
    "\n",
    "We will choose to implement MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b636da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mean_Squared_Error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean squared error (MSE) between two arrays.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (ndarray): Ground truth array of actual values.\n",
    "        y_pred (ndarray): Predicted array of values.\n",
    "    \n",
    "    Returns:\n",
    "        float: The mean squared error (MSE) between y_true and y_pred.\n",
    "    \"\"\"\n",
    "    # Calculate the squared differences between the two arrays\n",
    "    squared_diff = (y_true - y_pred) ** 2\n",
    "    \n",
    "    # Calculate the mean of the squared differences\n",
    "    mse = squared_diff.mean()\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "49328c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fct_test(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "dd2e327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.04830524e-32 -2.39544013e-32]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bfo = BFO_Model(2,fct_test)\n",
    "bfo.step()\n",
    "print(bfo.best_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12337389",
   "metadata": {},
   "source": [
    "# 2- Apply the BFO for N-N and compare it with the classical Backpropagation technique : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efa1435",
   "metadata": {},
   "source": [
    "## 2- 1- Define the classical backpropagation-based Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aaff89",
   "metadata": {},
   "source": [
    "in all this section we will work with a two layer regressing neural network\n",
    "\n",
    "**Note:**\n",
    "The input matrix is expected to have a shape of (m,n), where:\n",
    "\n",
    "m= number of examples\n",
    "\n",
    "n=nuber of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c1e7d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Classical_TwoLayerNet:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.params = {}\n",
    "        self.params['W1'] = np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.random.randn(hidden_size)\n",
    "        self.params['W2'] = np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.random.randn(output_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        # First layer\n",
    "        a1 = np.dot(X, self.params['W1']) + self.params['b1']\n",
    "        h1 = np.maximum(0, a1) # ReLU activation function\n",
    "        \n",
    "        # Second layer\n",
    "        a2 = np.dot(h1, self.params['W2']) + self.params['b2']\n",
    "        y = a2 # Output layer, using identity activation function\n",
    "        \n",
    "        # Save intermediate results for backpropagation\n",
    "        self.cache = (X, h1, a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def backward(self, y_true, y_pred, learning_rate):\n",
    "        \n",
    "        # Compute gradients\n",
    "        X, h1, a2 = self.cache\n",
    "        dy = y_pred - y_true\n",
    "        da2 = dy # Identity activation function\n",
    "        dW2 = np.dot(h1.T, da2)\n",
    "        db2 = np.sum(da2, axis=0)\n",
    "        dh1 = np.dot(da2, self.params['W2'].T)\n",
    "        da1 = dh1 * (h1 > 0) # ReLU activation function\n",
    "        dW1 = np.dot(X.T, da1)\n",
    "        db1 = np.sum(da1, axis=0)\n",
    "        \n",
    "        # Update weights\n",
    "        self.params['W1'] -= learning_rate * dW1\n",
    "        self.params['b1'] -= learning_rate * db1\n",
    "        self.params['W2'] -= learning_rate * dW2\n",
    "        self.params['b2'] -= learning_rate * db2\n",
    "    \n",
    "    def train(self, X_train, y_train, learning_rate, num_epochs):\n",
    "        \n",
    "        # Train the model\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # Forward pass\n",
    "            y_pred = self.forward(X_train)\n",
    "            \n",
    "            # Compute loss (MSE)\n",
    "            loss = np.mean((y_pred - y_train) ** 2)\n",
    "            \n",
    "            # Backward pass\n",
    "            self.backward(y_train, y_pred, learning_rate)\n",
    "            \n",
    "            # Print loss every 10 epochs\n",
    "            if epoch % 10 == 0:\n",
    "                print('Epoch %d, Loss = %f' % (epoch, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4858fd60",
   "metadata": {},
   "source": [
    "## 2- 1- The BFO based backpropagation for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "d458f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TwoLayerNet:\n",
    "    \n",
    "    \n",
    "    def Concate_parameters(self, params):\n",
    "        \"\"\"\n",
    "        this methods concatenates the dictionary params={'W1': [...] ,'b1': [...],'W2':[...],'b2':[...] }\n",
    "        \n",
    "        into a vector.\n",
    "        \"\"\"\n",
    "        params_vector = np.concatenate([\n",
    "            params['W1'].ravel(),\n",
    "            params['b1'].ravel(),\n",
    "            params['W2'].ravel(),\n",
    "            params['b2'].ravel()\n",
    "        ])\n",
    "        \n",
    "        return params_vector\n",
    "    \n",
    "    \n",
    "    \n",
    "    def Unconcatenating(self,params_vector,params):\n",
    "        \"\"\"\n",
    "         This method peermets to get back the original dictionary from the concatenate vector\n",
    "        \"\"\"\n",
    "        # Convert the vector 'params_vector' back to a dictionary 'params_dict'\n",
    "        params_dict = {}\n",
    "        w1_size = params['W1'].size\n",
    "        params_dict['W1'] = params_vector[:w1_size].reshape(params['W1'].shape)\n",
    "        b1_size = params['b1'].size\n",
    "        params_dict['b1'] = params_vector[w1_size:w1_size+b1_size]\n",
    "        w2_size = params['W2'].size\n",
    "        params_dict['W2'] = params_vector[w1_size+b1_size:w1_size+b1_size+w2_size].reshape(params['W2'].shape)\n",
    "        b2_size = params['b2'].size\n",
    "        params_dict['b2'] = params_vector[w1_size+b1_size+w2_size:]\n",
    "        \n",
    "        return params_dict\n",
    "        \n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size,X,y):\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.params = {}\n",
    "        self.params['W1'] = np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.random.randn(hidden_size)\n",
    "        self.params['W2'] = np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.random.randn(output_size)\n",
    "        \n",
    "        #Feature matrix\n",
    "        self.X = X \n",
    "        #the vector of outputs that correspond to all examples\n",
    "        self.y = y\n",
    "        \n",
    "        #flattern parameters into a vector\n",
    "        self.params_vector = self.Concate_parameters(self.params)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    def Mean_Squared_Error(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculates the mean squared error (MSE) between two arrays.\n",
    "\n",
    "        Parameters:\n",
    "            y_true (ndarray): Ground truth array of actual values.\n",
    "            y_pred (ndarray): Predicted array of values.\n",
    "\n",
    "        Returns:\n",
    "            float: The mean squared error (MSE) between y_true and y_pred.\n",
    "        \"\"\"\n",
    "        # Calculate the squared differences between the two arrays\n",
    "        squared_diff = (y_true - y_pred) ** 2\n",
    "\n",
    "        # Calculate the mean of the squared differences\n",
    "        mse = squared_diff.mean()\n",
    "\n",
    "        return mse\n",
    "    \n",
    "    \n",
    "    def forward(self,params_vector):\n",
    "        \n",
    "        \n",
    "        #1-unflattening the vector\n",
    "        self.params = self.Unconcatenating(params_vector,self.params)\n",
    "        \n",
    "        \n",
    "        #Note: we expect that X will have a shape :(m,input_size)\n",
    "        # First layer\n",
    "        a1 = np.dot(X, self.params['W1']) + self.params['b1']\n",
    "        h1 = np.maximum(0, a1) # ReLU activation function\n",
    "        \n",
    "        # Second layer\n",
    "        a2 = np.dot(h1, self.params['W2']) + self.params['b2']\n",
    "        y_pred = a2 # Output layer, using identity activation function\n",
    "        \n",
    "        return (self.Mean_Squared_Error(self.y, y_pred))**(-10)\n",
    "     \n",
    "        \n",
    "        \n",
    "    def BFO_based_backward(self):\n",
    "       \n",
    "      n = self.params_vector.size\n",
    "      \n",
    "      bfo = BFO_Model(n,self.forward)\n",
    "      bfo.step()\n",
    "      return bfo.best_position , bfo.best_fitness\n",
    "        \n",
    "         \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db9416",
   "metadata": {},
   "source": [
    "## 2-3 Comparison between the two methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1aab8",
   "metadata": {},
   "source": [
    "> ### 2-3-1 Classical back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "51f02ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = 0.307185\n",
      "Epoch 10, Loss = 0.035305\n",
      "Epoch 20, Loss = 0.035305\n",
      "Epoch 30, Loss = 0.035305\n",
      "Epoch 40, Loss = 0.035305\n",
      "Epoch 50, Loss = 0.035305\n",
      "Epoch 60, Loss = 0.035305\n",
      "Epoch 70, Loss = 0.035305\n",
      "Epoch 80, Loss = 0.035305\n",
      "Epoch 90, Loss = 0.035305\n"
     ]
    }
   ],
   "source": [
    "# Create training examples\n",
    "m = 10 # Number of examples\n",
    "n_inputs = 3 # Number of input units\n",
    "hidden_size = 4 # Number of units in the hidden layer\n",
    "output_size = 1 # Number of output units\n",
    "\n",
    "# Create training examples\n",
    "X = np.random.rand(m, n_inputs)\n",
    "y = np.random.rand(m, output_size)\n",
    "\n",
    "# Create a neural network\n",
    "model = Classical_TwoLayerNet(n_inputs, hidden_size, output_size)\n",
    "\n",
    "# Train the neural network\n",
    "model.train(X, y, 0.1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0029d0",
   "metadata": {},
   "source": [
    "> ### 2-3-1 BFO back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "8c0ab7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m= 10 #nbre of examples\n",
    "n_inputs = 3 #nbr of input units\n",
    "hidden_size = 4 # nbre of units in the hidden layer\n",
    "output_size = 1 # nbre of output units\n",
    "\n",
    "#create training example\n",
    "X=np.random.rand(m,n_inputs)\n",
    "y=np.random.rand(m)\n",
    "\n",
    "\n",
    "two_layer_N_N = TwoLayerNet(n_inputs,hidden_size,output_size,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "f172191c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([206.91468832, 131.97570939,  98.65657065, 249.32685283,\n",
       "        241.05090343, 180.51243426, 210.90334013, 182.64341602,\n",
       "        -21.24018487, 166.94363068, 178.44858239, 110.95528653,\n",
       "        134.86488788, 205.02338229, 178.27710241, 188.75468237,\n",
       "         72.21384803, 120.03174415, 143.91374881, 208.79666851,\n",
       "         55.21897237]),\n",
       " 8.638278832909169e-109)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "two_layer_N_N.BFO_based_backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d94fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
